{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os import path\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from os.path import basename, splitext\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'frank'\n",
    "\n",
    "RM = 1.5\n",
    "GM = 0.8\n",
    "h_min = 32\n",
    "h_max = 48\n",
    "max_n_diff = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frankfurt_db=0.50', 'frankfurt_db=1.00', 'frankfurt_db=2.00', 'frankfurt_db=4.00']\n"
     ]
    }
   ],
   "source": [
    "list_city_dt = []\n",
    "\n",
    "for file_in in os.listdir(r'../instances'):\n",
    "    base_file = splitext(basename(file_in))[0]\n",
    "    base_file_split = base_file.split('_')\n",
    "    file = base_file_split[0]+'_'+base_file_split[1]\n",
    "    list_city_dt.append(file)\n",
    "\n",
    "list_city_dt = list(set(list_city_dt))\n",
    "list_city_dt.sort()\n",
    "\n",
    "#Subset to city\n",
    "list_city_dt_subset = []\n",
    "\n",
    "for city_db in list_city_dt:\n",
    "    if (city_db.find(city) > -1):\n",
    "        list_city_dt_subset.append(city_db)\n",
    "\n",
    "print(list_city_dt_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_file = 'frankfurt_db=0.50'\n",
    "OC = 1.2\n",
    "model = 'flex'\n",
    "max_n_shifts = None\n",
    "\n",
    "if max_n_shifts is None:\n",
    "    results_file = f\"../raw_results/{base_file}_OC={OC}_model={model}.pkl\"\n",
    "else:\n",
    "    results_file = f\"../raw_results/{base_file}_OC={OC}_model={model}_max_n_shifts={max_n_shifts}.pkl\"\n",
    "\n",
    "with open(results_file, 'rb') as file:\n",
    "    sol = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- COSTS ---\n",
      "    Objective value: 1498.8799999996988 \n",
      "    Hiring costs: 288 \n",
      "    Outsourcing costs: 1210.8799999996988\n"
     ]
    }
   ],
   "source": [
    "# Costs\n",
    "print('--- COSTS ---')\n",
    "obj_val = sol['obj_val']\n",
    "hiring_costs = sum( (employee, shift_start, day) in sol['r']\n",
    "                   for region in sol['regions']\n",
    "                   for employee in sol['employees'][region]\n",
    "                   for day in sol['days']\n",
    "                   for shift_start in sol['shifts'][(region, day)] )\n",
    "outsourcing_costs = obj_val - hiring_costs\n",
    "print(f'    Objective value: {obj_val} \\n    Hiring costs: {hiring_costs} \\n    Outsourcing costs: {outsourcing_costs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- HOURS WORKED ---\n",
      "    Overall hours worked pct: 68.57142857142857\n",
      "    Mean hours pct per employee: 68.57142857142857\n",
      "    Std hours pct per employee: 6.6325658462781565\n",
      "    Quantile 25 hours pct per employee: 66.66666666666666\n",
      "    Median 25 hours pct per employee: 66.66666666666666\n",
      "    Quantile 75 hours pct per employee: 66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "# Hours worked\n",
    "print('--- HOURS WORKED ---')\n",
    "people_hired = sum( 1\n",
    "                   for region in sol['regions']\n",
    "                   for employee in sol['employees'][region])\n",
    "\n",
    "hours_worked_pct = sum(\n",
    "    (employee, area, theta, day) in sol['k']\n",
    "    for day in sol['days']\n",
    "    for region in sol['regions']\n",
    "    for employee in sol['employees'][region]\n",
    "    for area in sol['reg_areas'][region]\n",
    "    for theta in sol['periods'][day]\n",
    ") / (people_hired * sol['hmax'] / 2) * 100 # hours per period \n",
    "\n",
    "print(f'    Overall hours worked pct: {hours_worked_pct}')\n",
    "\n",
    "employee_hours = {}\n",
    "for region in sol['regions']:\n",
    "    for employee in sol['employees'][region]:\n",
    "        employee_hours[employee] = sum(\n",
    "            (employee, area, theta, day) in sol['k']\n",
    "            for day in sol['days']\n",
    "            for area in sol['reg_areas'][region]\n",
    "            for theta in sol['periods'][day]\n",
    "        ) / (sol['hmax'] / 2) * 100 # hours per period\n",
    "\n",
    "print(f'    Mean hours pct per employee: {np.mean(list(employee_hours.values()))}')\n",
    "print(f'    Std hours pct per employee: {np.std(list(employee_hours.values()))}')\n",
    "print(f'    Quantile 25 hours pct per employee: {np.quantile(list(employee_hours.values()), 0.25)}')\n",
    "print(f'    Median 25 hours pct per employee: {np.median(list(employee_hours.values()))}')\n",
    "print(f'    Quantile 75 hours pct per employee: {np.quantile(list(employee_hours.values()), 0.75)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SHIFTS STARTS ---\n",
      "    Mean shifts start: 2.342857142857143\n",
      "    Quantile 25 shifts start: 2.0\n",
      "    Quantile 50 shifts start: 2.0\n",
      "    Quantile 75 shifts start: 3.0\n",
      "--- SELECTED SHIFTS ---\n",
      "    Utilization rate of shifts: 58.57142857142858\n"
     ]
    }
   ],
   "source": [
    "# Starting shifts \n",
    "print('--- SHIFTS STARTS ---')\n",
    "employee_starts = []\n",
    "# self.r[(employee, shift_start, day)]\n",
    "for region in sol['regions']:\n",
    "    for employee in sol['employees'][region]:\n",
    "        for day in sol['days']:\n",
    "            for shift_start in sol['shifts'][(region, day)]:\n",
    "                if (employee, shift_start, day) in sol['r']:\n",
    "                    employee_starts.append({'employee': employee, 'shift_start': shift_start, 'day': day})\n",
    "\n",
    "employee_starts_df = pd.DataFrame(employee_starts)\n",
    "emp_ = employee_starts_df.groupby(\"employee\").agg({\"shift_start\": \"nunique\"})[\"shift_start\"]\n",
    "print(f'    Mean shifts start: {emp_.mean()}')\n",
    "print(f'    Quantile 25 shifts start: {emp_.quantile(0.25)}')\n",
    "print(f'    Quantile 50 shifts start: {emp_.quantile(0.5)}')\n",
    "print(f'    Quantile 75 shifts start: {emp_.quantile(0.75)}')\n",
    "\n",
    "print('--- SELECTED SHIFTS ---')\n",
    "_ = employee_starts_df.groupby('shift_start').agg({'employee': 'nunique'})\n",
    "num_employees = employee_starts_df['employee'].nunique()\n",
    "print(f'    Utilization rate of shifts: {_[\"employee\"].mean() / num_employees * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for base_file in list_city_dt_subset:\n",
    "    for OC in [1.2, 1.5, 1.8, 2.0, 2.5]:\n",
    "    # for OC in [1.2]:\n",
    "        for model in ['fixed', 'flex', 'partflex']:\n",
    "        # for model in ['fixed']:\n",
    "            if model == 'partflex':\n",
    "                for max_n_shifts in range(2,5):\n",
    "                    # Save results\n",
    "                    results_file = f\"../raw_results/{base_file}_OC={OC}_model={model}_max_n_shifts={max_n_shifts}.pkl\"\n",
    "                    #with open(results_file, 'wb') as file:\n",
    "                    #    pickle.dump(dict_results, file)\n",
    "                    #print(f'instance_results saved to {results_file}')\n",
    "            else:\n",
    "                # Save results\n",
    "                results_file = f\"../raw_results/{base_file}_OC={OC}_model={model}.pkl\"\n",
    "                #with open(results_file, 'wb') as file:\n",
    "                #    pickle.dump(dict_results, file)\n",
    "                #print(f'instance_results saved to {results_file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
