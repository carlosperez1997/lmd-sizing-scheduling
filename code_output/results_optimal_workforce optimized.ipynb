{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os import path\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from os.path import basename, splitext\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# from solver import Instance\n",
    "\n",
    "from argparse import Namespace\n",
    "import sys\n",
    "sys.path.append('../solver')\n",
    "# from solver_output import practice_print\n",
    "from solver_rostering import run_roster_solver_objval_w_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'paris'\n",
    "\n",
    "# fixed params\n",
    "RM = 1.5\n",
    "GM = 0.8\n",
    "h_min = 32\n",
    "h_max = 48\n",
    "max_n_diff = 3\n",
    "\n",
    "refresh = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paris_db=0.50', 'paris_db=1.00', 'paris_db=2.00', 'paris_db=4.00']\n"
     ]
    }
   ],
   "source": [
    "list_city_dt = []\n",
    "\n",
    "for file_in in os.listdir(r'../instances'):\n",
    "    base_file = splitext(basename(file_in))[0]\n",
    "    base_file_split = base_file.split('_')\n",
    "    file = base_file_split[0]+'_'+base_file_split[1]\n",
    "    list_city_dt.append(file)\n",
    "\n",
    "list_city_dt = list(set(list_city_dt))\n",
    "list_city_dt.sort()\n",
    "\n",
    "#Subset to frankfurt\n",
    "list_city_dt_subset = []\n",
    "\n",
    "for city_db in list_city_dt:\n",
    "    if (city_db.find(city) > -1):\n",
    "        list_city_dt_subset.append(city_db)\n",
    "\n",
    "print(list_city_dt_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shift(shift_file, OC, RM, GM, model, max_n_shifts=None):\n",
    "    with open(shift_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        df_shifts = pd.DataFrame(data)\n",
    "    df_shifts = df_shifts[(df_shifts['outsourcing_cost_multiplier']==OC)&(df_shifts['regional_multiplier']==RM)&(df_shifts['global_multiplier']==GM)]\n",
    "    #fixed or flex\n",
    "    if model in ['fixed','flex']:\n",
    "        df_shifts = df_shifts[df_shifts['model']==model]\n",
    "    #partflex\n",
    "    else:\n",
    "        df_shifts = df_shifts[(df_shifts['model']==model)&(df_shifts['max_n_shifts']==max_n_shifts)]\n",
    "    df_shifts.reset_index(drop = True, inplace=True)\n",
    "    df_shifts = df_shifts[['region','shifts_start','shifts_end']]\n",
    "    dict_shifts = df_shifts.set_index('region').to_dict(orient='index')\n",
    "    return dict_shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_workforce(workforce_file, OC, RM, GM, model, max_n_shifts=None):\n",
    "    with open(workforce_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        df_workforce = pd.DataFrame(data)\n",
    "    df_workforce = df_workforce[(df_workforce['outsourcing_cost_multiplier']==OC)&(df_workforce['regional_multiplier']==RM)&(df_workforce['global_multiplier']==GM)]\n",
    "    #fixed or flex\n",
    "    if model in ['fixed','flex']:\n",
    "        df_workforce = df_workforce[df_workforce['model']==model]\n",
    "    #partflex\n",
    "    else:\n",
    "        df_workforce = df_workforce[(df_workforce['model']==model)&(df_workforce['max_n_shifts']==max_n_shifts)]\n",
    "    df_workforce.reset_index(drop = True, inplace=True)\n",
    "    return (int(df_workforce['workforce_size_region0'].tolist()[0])-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base: paris_db=0.50, OC: 1.2, model: flex, run_time: 22.05417490005493\n",
      "Base: paris_db=0.50, OC: 1.2, model: partflex-4, already solved. Saving previous results\n",
      "Base: paris_db=0.50, OC: 1.2, model: partflex-3, already solved. Saving previous results\n",
      "Base: paris_db=0.50, OC: 1.2, model: partflex-2, run_time: 11.245937824249268\n",
      "Base: paris_db=0.50, OC: 1.2, model: fixed, already solved. Saving previous results\n",
      "Base: paris_db=0.50, OC: 1.5, model: flex, run_time: 36.49060893058777\n",
      "Base: paris_db=0.50, OC: 1.5, model: partflex-4, already solved. Saving previous results\n",
      "Base: paris_db=0.50, OC: 1.5, model: partflex-3, already solved. Saving previous results\n",
      "Base: paris_db=0.50, OC: 1.5, model: partflex-2, run_time: 9.270392179489136\n",
      "Base: paris_db=0.50, OC: 1.5, model: fixed, already solved. Saving previous results\n",
      "Base: paris_db=0.50, OC: 1.8, model: flex, run_time: 40.848809003829956\n",
      "Base: paris_db=0.50, OC: 1.8, model: partflex-4, already solved. Saving previous results\n",
      "Base: paris_db=0.50, OC: 1.8, model: partflex-3, already solved. Saving previous results\n",
      "Base: paris_db=0.50, OC: 1.8, model: partflex-2, run_time: 9.9513840675354\n",
      "Base: paris_db=0.50, OC: 1.8, model: fixed, already solved. Saving previous results\n",
      "Base: paris_db=0.50, OC: 2.0, model: flex, run_time: 25.268577098846436\n",
      "Base: paris_db=0.50, OC: 2.0, model: partflex-4, already solved. Saving previous results\n",
      "Base: paris_db=0.50, OC: 2.0, model: partflex-3, already solved. Saving previous results\n",
      "Base: paris_db=0.50, OC: 2.0, model: partflex-2, run_time: 10.164016008377075\n",
      "Base: paris_db=0.50, OC: 2.0, model: fixed, already solved. Saving previous results\n",
      "Base: paris_db=0.50, OC: 2.5, model: flex, run_time: 50.97735023498535\n",
      "Base: paris_db=0.50, OC: 2.5, model: partflex-4, already solved. Saving previous results\n",
      "Base: paris_db=0.50, OC: 2.5, model: partflex-3, already solved. Saving previous results\n",
      "Base: paris_db=0.50, OC: 2.5, model: partflex-2, run_time: 10.754328966140747\n",
      "Base: paris_db=0.50, OC: 2.5, model: fixed, already solved. Saving previous results\n",
      "Base: paris_db=1.00, OC: 1.2, model: flex, run_time: 230.84547209739685\n",
      "Base: paris_db=1.00, OC: 1.2, model: partflex-4, already solved. Saving previous results\n",
      "Base: paris_db=1.00, OC: 1.2, model: partflex-3, already solved. Saving previous results\n",
      "Base: paris_db=1.00, OC: 1.2, model: partflex-2, run_time: 15.829065084457397\n",
      "Base: paris_db=1.00, OC: 1.2, model: fixed, already solved. Saving previous results\n",
      "Base: paris_db=1.00, OC: 1.5, model: flex, run_time: 69.98183822631836\n",
      "Base: paris_db=1.00, OC: 1.5, model: partflex-4, already solved. Saving previous results\n",
      "Base: paris_db=1.00, OC: 1.5, model: partflex-3, already solved. Saving previous results\n",
      "Base: paris_db=1.00, OC: 1.5, model: partflex-2, run_time: 16.758832931518555\n",
      "Base: paris_db=1.00, OC: 1.5, model: fixed, already solved. Saving previous results\n",
      "Base: paris_db=1.00, OC: 1.8, model: flex, run_time: 190.2589716911316\n",
      "Base: paris_db=1.00, OC: 1.8, model: partflex-4, already solved. Saving previous results\n",
      "Base: paris_db=1.00, OC: 1.8, model: partflex-3, already solved. Saving previous results\n",
      "Base: paris_db=1.00, OC: 1.8, model: partflex-2, run_time: 17.297356843948364\n",
      "Base: paris_db=1.00, OC: 1.8, model: fixed, already solved. Saving previous results\n",
      "Base: paris_db=1.00, OC: 2.0, model: flex, run_time: 325.63441467285156\n",
      "Base: paris_db=1.00, OC: 2.0, model: partflex-4, already solved. Saving previous results\n",
      "Base: paris_db=1.00, OC: 2.0, model: partflex-3, already solved. Saving previous results\n",
      "Base: paris_db=1.00, OC: 2.0, model: partflex-2, run_time: 17.770071983337402\n",
      "Base: paris_db=1.00, OC: 2.0, model: fixed, already solved. Saving previous results\n",
      "Base: paris_db=1.00, OC: 2.5, model: flex, run_time: 407.9882709980011\n",
      "Base: paris_db=1.00, OC: 2.5, model: partflex-4, already solved. Saving previous results\n",
      "Base: paris_db=1.00, OC: 2.5, model: partflex-3, already solved. Saving previous results\n",
      "Base: paris_db=1.00, OC: 2.5, model: partflex-2, run_time: 19.115757942199707\n",
      "Base: paris_db=1.00, OC: 2.5, model: fixed, already solved. Saving previous results\n",
      "Base: paris_db=2.00, OC: 1.2, model: flex, run_time: 1318.7515921592712\n",
      "Base: paris_db=2.00, OC: 1.2, model: partflex-4, already solved. Saving previous results\n",
      "Base: paris_db=2.00, OC: 1.2, model: partflex-3, already solved. Saving previous results\n",
      "Base: paris_db=2.00, OC: 1.2, model: partflex-2, run_time: 29.443801879882812\n",
      "Base: paris_db=2.00, OC: 1.2, model: fixed, already solved. Saving previous results\n",
      "Base: paris_db=2.00, OC: 1.5, model: flex, run_time: 149.785227060318\n",
      "Base: paris_db=2.00, OC: 1.5, model: partflex-4, already solved. Saving previous results\n",
      "Base: paris_db=2.00, OC: 1.5, model: partflex-3, already solved. Saving previous results\n",
      "Base: paris_db=2.00, OC: 1.5, model: partflex-2, run_time: 30.925057888031006\n",
      "Base: paris_db=2.00, OC: 1.5, model: fixed, already solved. Saving previous results\n",
      "Base: paris_db=2.00, OC: 1.8, model: flex, run_time: 1422.7489559650421\n",
      "Base: paris_db=2.00, OC: 1.8, model: partflex-4, already solved. Saving previous results\n",
      "Base: paris_db=2.00, OC: 1.8, model: partflex-3, already solved. Saving previous results\n",
      "Base: paris_db=2.00, OC: 1.8, model: partflex-2, run_time: 32.34196925163269\n",
      "Base: paris_db=2.00, OC: 1.8, model: fixed, already solved. Saving previous results\n",
      "Base: paris_db=2.00, OC: 2.0, model: flex, run_time: 1338.9246258735657\n",
      "Base: paris_db=2.00, OC: 2.0, model: partflex-4, already solved. Saving previous results\n",
      "Base: paris_db=2.00, OC: 2.0, model: partflex-3, already solved. Saving previous results\n",
      "Base: paris_db=2.00, OC: 2.0, model: partflex-2, run_time: 33.59609007835388\n",
      "Base: paris_db=2.00, OC: 2.0, model: fixed, already solved. Saving previous results\n",
      "Base: paris_db=2.00, OC: 2.5, model: flex, run_time: 20742.374916791916\n",
      "Base: paris_db=2.00, OC: 2.5, model: partflex-4, already solved. Saving previous results\n",
      "Base: paris_db=2.00, OC: 2.5, model: partflex-3, already solved. Saving previous results\n",
      "Base: paris_db=2.00, OC: 2.5, model: partflex-2, run_time: 44.26509094238281\n",
      "Base: paris_db=2.00, OC: 2.5, model: fixed, already solved. Saving previous results\n",
      "Base: paris_db=4.00, OC: 1.2, model: flex, run_time: 13184.863773107529\n",
      "Base: paris_db=4.00, OC: 1.2, model: partflex-4, already solved. Saving previous results\n",
      "Base: paris_db=4.00, OC: 1.2, model: partflex-3, already solved. Saving previous results\n",
      "Base: paris_db=4.00, OC: 1.2, model: partflex-2, run_time: 82.76740503311157\n",
      "Base: paris_db=4.00, OC: 1.2, model: fixed, already solved. Saving previous results\n",
      "\n",
      "Interrupt request received\n",
      "Base: paris_db=4.00, OC: 1.5, model: flex, run_time: 10536.948539018631\n",
      "Base: paris_db=4.00, OC: 1.5, model: partflex-4, already solved. Saving previous results\n",
      "Base: paris_db=4.00, OC: 1.5, model: partflex-3, already solved. Saving previous results\n",
      "Base: paris_db=4.00, OC: 1.5, model: partflex-2, run_time: 86.03235197067261\n",
      "Base: paris_db=4.00, OC: 1.5, model: fixed, already solved. Saving previous results\n"
     ]
    }
   ],
   "source": [
    "for base_file in list_city_dt_subset:\n",
    "\n",
    "    #create inputs to run a trial workforce size\n",
    "    weekday_ = f'{base_file}_dt=doublepeak.json'\n",
    "    weekend_ = f'{base_file}_dt=uniform.json'\n",
    "\n",
    "    instance_file_weekday = f\"../instances/{weekday_}\"\n",
    "    instance_file_weekend = f\"../instances/{weekend_}\"\n",
    "\n",
    "    shift_file_weekday = f\"../shifts/{weekday_}\"\n",
    "    shift_file_weekend = f\"../shifts/{weekend_}\"\n",
    "\n",
    "    expand_workforce_to_regions=True\n",
    "    workforce_dict = {}\n",
    "\n",
    "    new_shift_weekend = None\n",
    "    new_shift_weekday = None\n",
    "    new_workforce = None\n",
    "    dict_results = {}\n",
    "\n",
    "    for OC in [1.2, 1.5, 1.8, 2.0, 2.5]:\n",
    "\n",
    "        new_shift_weekend = None\n",
    "        new_shift_weekday = None\n",
    "        new_workforce = None\n",
    "        dict_results = {}\n",
    "\n",
    "        for model in ['flex',  'partflex', 'fixed']:\n",
    "            if model == 'partflex':\n",
    "                for max_n_shifts in [4, 3, 2]:\n",
    "\n",
    "                    old_results = dict_results\n",
    "                    results_file = f\"../raw_results/{base_file}_OC={OC}_model={model}_max_n_shifts={max_n_shifts}.pkl\"\n",
    "\n",
    "                    # Check if shift pattern is already solved\n",
    "                    old_workforce = new_workforce\n",
    "                    new_workforce = load_workforce(f'../workforce_size/{base_file}.json', OC, RM, GM, model, max_n_shifts)\n",
    "                    old_shift_weekend = new_shift_weekend\n",
    "                    old_shift_weekday = new_shift_weekday\n",
    "                    new_shift_weekend = load_shift(shift_file_weekend, OC, RM, GM, model, max_n_shifts)\n",
    "                    new_shift_weekday = load_shift(shift_file_weekday, OC, RM, GM, model, max_n_shifts)\n",
    "\n",
    "                    if old_shift_weekend == new_shift_weekend and old_shift_weekday == new_shift_weekday and old_workforce == new_workforce:\n",
    "                        old_results['baseline']['model']  = [model]\n",
    "                        old_results['baseline']['max_n_shifts'] = max_n_shifts\n",
    "\n",
    "                        print(f'Base: {base_file}, OC: {OC}, model: {model}-{max_n_shifts}, already solved. Saving previous results')\n",
    "\n",
    "                        # Save previous results\n",
    "                        with open(results_file, 'wb') as file:\n",
    "                            pickle.dump(old_results, file)\n",
    "                        continue\n",
    "                    \n",
    "                    start_time = time.time()\n",
    "                    dict_baseline, dict_results = \\\n",
    "                        run_roster_solver_objval_w_baseline(model, instance_file_weekday, \n",
    "                                                            shift_file_weekday, instance_file_weekend, \n",
    "                                                            shift_file_weekend, workforce_dict, \n",
    "                                                            OC, RM, GM, h_min, h_max, max_n_diff, \n",
    "                                                            max_n_shifts, expand_workforce_to_regions=True)\n",
    "                    \n",
    "                    dict_results['baseline'] = dict_baseline\n",
    "                    end_time = time.time()\n",
    "                    run_time = (end_time - start_time)\n",
    "                    \n",
    "                    # Save results\n",
    "                    with open(results_file, 'wb') as file:\n",
    "                        pickle.dump(dict_results, file)\n",
    "                    print(f'Base: {base_file}, OC: {OC}, model: {model}-{max_n_shifts}, run_time: {run_time}')\n",
    "\n",
    "            else:\n",
    "\n",
    "                old_results = dict_results\n",
    "                results_file = f\"../raw_results/{base_file}_OC={OC}_model={model}.pkl\"\n",
    "\n",
    "                # Check if shift pattern is already solved\n",
    "                old_workforce = new_workforce\n",
    "                new_workforce = load_workforce(f'../workforce_size/{base_file}.json', OC, RM, GM, model)\n",
    "\n",
    "                old_shift_weekend = new_shift_weekend\n",
    "                old_shift_weekday = new_shift_weekday\n",
    "                new_shift_weekend = load_shift(shift_file_weekend, OC, RM, GM, model)\n",
    "                new_shift_weekday = load_shift(shift_file_weekday, OC, RM, GM, model)\n",
    "\n",
    "                if old_shift_weekend == new_shift_weekend and old_shift_weekday == new_shift_weekday and old_workforce == new_workforce:\n",
    "                    old_results['baseline']['model']  = [model]\n",
    "                    if 'max_n_shifts' in old_results['baseline']:\n",
    "                        old_results['baseline']['max_n_shifts'] = None\n",
    "                \n",
    "                    print(f'Base: {base_file}, OC: {OC}, model: {model}, already solved. Saving previous results')\n",
    "        \n",
    "                    # Save previous results\n",
    "                    with open(results_file, 'wb') as file:\n",
    "                        pickle.dump(old_results, file)\n",
    "                    continue\n",
    "                \n",
    "                results_file = f\"../raw_results/{base_file}_OC={OC}_model={model}.pkl\"\n",
    "                # if not os.path.exists(results_file) or refresh:\n",
    "                start_time = time.time()\n",
    "                dict_baseline, dict_results = \\\n",
    "                    run_roster_solver_objval_w_baseline(model, instance_file_weekday, \n",
    "                                                        shift_file_weekday, instance_file_weekend, \n",
    "                                                        shift_file_weekend, workforce_dict, \n",
    "                                                        OC, RM, GM, h_min, h_max, max_n_diff, \n",
    "                                                        expand_workforce_to_regions=True)\n",
    "                \n",
    "                dict_results['baseline'] = dict_baseline\n",
    "                end_time = time.time()\n",
    "                run_time = (end_time - start_time)\n",
    "\n",
    "                # Save results\n",
    "                with open(results_file, 'wb') as file:\n",
    "                    pickle.dump(dict_results, file)\n",
    "                print(f'Base: {base_file}, OC: {OC}, model: {model}, run_time: {run_time}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workforce = load_workforce(f'../workforce_size/{base_file}.json', OC, RM, GM, model, max_n_shifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fixed']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_results['baseline']['model']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
