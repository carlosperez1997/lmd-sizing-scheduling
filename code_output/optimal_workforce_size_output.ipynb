{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os import path\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.legend_handler import HandlerTuple\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from os.path import basename, splitext\n",
    "\n",
    "# from solver import Instance\n",
    "\n",
    "from argparse import Namespace\n",
    "import sys\n",
    "sys.path.append('../solver')\n",
    "# from solver_output import practice_print\n",
    "from solver_rostering import run_roster_solver_objval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frankfurt_db=4.00', 'berlin_db=0.50', 'paris_db=1.00', 'lyon_db=2.00', 'paris_db=4.00', 'berlin_db=1.00', 'lyon_db=1.00', 'lyon_db=4.00', 'frankfurt_db=0.50', 'berlin_db=2.00', 'berlin_db=4.00', 'frankfurt_db=1.00', 'frankfurt_db=2.00', 'paris_db=0.50', 'paris_db=2.00', 'lyon_db=0.50']\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "list_city_dt = []\n",
    "\n",
    "for file_in in os.listdir(r'../instances'):\n",
    "    base_file = splitext(basename(file_in))[0]\n",
    "    base_file_split = base_file.split('_')\n",
    "    file = base_file_split[0]+'_'+base_file_split[1]\n",
    "    list_city_dt.append(file)\n",
    "\n",
    "list_city_dt = list(set(list_city_dt))\n",
    "print(list_city_dt)\n",
    "print(len(list_city_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_append_workforce(dict_, base_file, city, demand_baseline, OC, RM, GM, model, max_n_shifts, workforce_size, objvalprev, objval, objvalnext):\n",
    "    dict_['instance_file_base'].append(base_file)\n",
    "    dict_['city'].append(city)\n",
    "    dict_['demand_baseline'].append(demand_baseline)\n",
    "    dict_['model'].append(model)\n",
    "    dict_['max_n_shifts'].append(max_n_shifts)\n",
    "    dict_['outsourcing_cost_multiplier'].append(OC)\n",
    "    dict_['regional_multiplier'].append(RM)\n",
    "    dict_['global_multiplier'].append(GM)\n",
    "    dict_['workforce_size_region0'].append(workforce_size)\n",
    "    dict_['objective_value_prev'].append(objvalprev)\n",
    "    dict_['objective_value'].append(objval)\n",
    "    dict_['objective_value_next'].append(objvalnext)\n",
    "    return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "base_file = 'berlin_db=1.00'\n",
    "weekday_ = f'{base_file}_dt=doublepeak.json'\n",
    "instance_file_weekday = f\"../instances/{weekday_}\"\n",
    "\n",
    "# Specify the file path\n",
    "file_path = '/path/to/your/file.json'\n",
    "\n",
    "# Open the JSON file\n",
    "with open(instance_file_weekday, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "region_data = data['geography']['city']['regions']\n",
    "region_ids = [region['id'] for region in region_data]\n",
    "\n",
    "# build workforce dictionary\n",
    "workforce_dict = {}\n",
    "for region in range(max(region_ids)+1):\n",
    "    workforce_dict[region] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 5, 1: 1, 2: 1, 3: 1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workforce_dict[0] = 5\n",
    "workforce_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-10-12\n",
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[rosetta2])\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 99724 rows, 102488 columns and 157416 nonzeros\n",
      "Model fingerprint: 0xc98a953b\n",
      "Variable types: 99120 continuous, 3368 integer (3368 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+01]\n",
      "  Objective range  [3e-02, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 5e+01]\n",
      "Presolve removed 99724 rows and 102488 columns\n",
      "Presolve time: 0.08s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.12 seconds (0.11 work units)\n",
      "Thread count was 1 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 7587.05 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 7.587053333328e+03, best bound 7.587053333328e+03, gap 0.0000%\n",
      "trial_size 1\n",
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[rosetta2])\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 99875 rows, 103064 columns and 173466 nonzeros\n",
      "Model fingerprint: 0xd80a3b46\n",
      "Variable types: 99120 continuous, 3944 integer (3944 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+01]\n",
      "  Objective range  [3e-02, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 5e+01]\n",
      "Found heuristic solution: objective 7706.3067093\n",
      "Presolve removed 99064 rows and 100856 columns\n",
      "Presolve time: 0.12s\n",
      "Presolved: 811 rows, 2208 columns, 5734 nonzeros\n",
      "Found heuristic solution: objective 7589.9266667\n",
      "Variable types: 1030 continuous, 1178 integer (1178 binary)\n",
      "\n",
      "Root relaxation: objective 7.527167e+03, 1356 iterations, 0.01 seconds (0.01 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    7527.1666667 7527.16667  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (1356 simplex iterations) in 0.21 seconds (0.14 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 7527.17 7589.93 7706.31 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 7.527166666662e+03, best bound 7.527166666662e+03, gap 0.0000%\n",
      "trial_size 2\n",
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[rosetta2])\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 100026 rows, 103640 columns and 189516 nonzeros\n",
      "Model fingerprint: 0x390f25a4\n",
      "Variable types: 99120 continuous, 4520 integer (4520 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+01]\n",
      "  Objective range  [3e-02, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 5e+01]\n",
      "Found heuristic solution: objective 7673.4333760\n",
      "Presolve removed 99087 rows and 100513 columns\n",
      "Presolve time: 0.12s\n",
      "Presolved: 939 rows, 3127 columns, 8416 nonzeros\n",
      "Found heuristic solution: objective 7548.4933336\n",
      "Variable types: 1380 continuous, 1747 integer (1747 binary)\n",
      "\n",
      "Root relaxation: objective 7.469287e+03, 2105 iterations, 0.01 seconds (0.02 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    7469.2866667 7469.28667  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (2105 simplex iterations) in 0.22 seconds (0.17 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 7469.29 7548.49 7673.43 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 7.469286666662e+03, best bound 7.469286666662e+03, gap 0.0000%\n",
      "trial_size 3\n",
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[rosetta2])\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 100177 rows, 104216 columns and 205566 nonzeros\n",
      "Model fingerprint: 0x114c5b49\n",
      "Variable types: 99120 continuous, 5096 integer (5096 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+01]\n",
      "  Objective range  [3e-02, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 5e+01]\n",
      "Found heuristic solution: objective 7643.7867095\n",
      "Presolve removed 99110 rows and 100485 columns\n",
      "Presolve time: 0.12s\n",
      "Presolved: 1067 rows, 3731 columns, 10783 nonzeros\n",
      "Found heuristic solution: objective 7532.4466667\n",
      "Variable types: 1415 continuous, 2316 integer (2316 binary)\n",
      "\n",
      "Root relaxation: objective 7.414587e+03, 2639 iterations, 0.02 seconds (0.03 work units)\n",
      "\n",
      "Interrupt request received\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    7414.5866667 7414.58667  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (2982 simplex iterations) in 0.25 seconds (0.20 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 7414.59 7532.45 7643.79 \n",
      "\n",
      "Solve interrupted\n",
      "Best objective 7.414586666662e+03, best bound 7.414586666662e+03, gap 0.0000%\n",
      "trial_size 4\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../workforce_size/berlin_db=1.00.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 110\u001b[0m\n\u001b[1;32m    108\u001b[0m                     dict_out \u001b[38;5;241m=\u001b[39m dict_append_workforce(dict_out, base_file, city, demand_baseline, OC, RM, GM, model, np\u001b[38;5;241m.\u001b[39mnan, trial_size, objvalprev, objval, np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m#export optimal workforce size values\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mworkforce_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    111\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(dict_out, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tsp/lib/python3.11/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../workforce_size/berlin_db=1.00.json'"
     ]
    }
   ],
   "source": [
    "list_results = []\n",
    "\n",
    "MAX_TRIES = 35\n",
    "\n",
    "RM = 1.5\n",
    "GM = 0.8\n",
    "h_min = 32\n",
    "h_max = 48\n",
    "max_n_diff = 3\n",
    "\n",
    "# for base_file in list_city_dt:\n",
    "for base_file in ['berlin_db=1.00']:\n",
    "\n",
    "    #create inputs to run a trial workforce size\n",
    "    weekday_ = f'{base_file}_dt=doublepeak.json'\n",
    "    weekend_ = f'{base_file}_dt=uniform.json'\n",
    "\n",
    "    instance_file_weekday = f\"../instances/{weekday_}\"\n",
    "    instance_file_weekend = f\"../instances/{weekend_}\"\n",
    "\n",
    "    shift_file_weekday = f\"../shifts/{weekday_}\"\n",
    "    shift_file_weekend = f\"../shifts/{weekend_}\"\n",
    "\n",
    "    #create dictionary for evaluating optimal workforce size\n",
    "    workforce_out = f\"../workforce_size/{base_file}.json\"\n",
    "    dict_out = {\n",
    "        'instance_file_base':[],\n",
    "        'city':[],\n",
    "        'demand_baseline':[],\n",
    "        'model':[],\n",
    "        'max_n_shifts':[],\n",
    "        'outsourcing_cost_multiplier':[],\n",
    "        'regional_multiplier':[],\n",
    "        'global_multiplier':[],\n",
    "        'workforce_size_region0':[],\n",
    "        'objective_value_prev':[],\n",
    "        'objective_value':[],\n",
    "        'objective_value_next':[]\n",
    "    }\n",
    "\n",
    "    city_pattern = r'(\\w+)_db'\n",
    "    db_pattern = r'db=(\\d+\\.\\d+)'\n",
    "\n",
    "    city_match = re.search(city_pattern, base_file)\n",
    "    db_match = re.search(db_pattern, base_file)\n",
    "\n",
    "    city = city_match.group(1) if city_match else None\n",
    "    demand_baseline = float(db_match.group(1)) if db_match else None\n",
    "\n",
    "    ### Build starting workforce dictionary\n",
    "    with open(instance_file_weekday, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Extract region IDs\n",
    "    region_data = data['geography']['city']['regions']\n",
    "    region_ids = [region['id'] for region in region_data]\n",
    "\n",
    "    # build workforce dictionary\n",
    "    workforce_dict = {}\n",
    "    for region in range(max(region_ids)+1):\n",
    "        workforce_dict[region] = 1\n",
    "\n",
    "    # for OC in [1.2, 1.5, 1.8, 2.0, 2.5]:\n",
    "    for OC in [1.2]:\n",
    "        # for model in ['fixed', 'flex', 'partflex']:\n",
    "        for model in ['fixed']:\n",
    "            if model == 'partflex':\n",
    "                # for max_n_shifts in range(2,5):\n",
    "                for max_n_shifts in [4]:\n",
    "                    objvalprev = 1e8\n",
    "                    objval = 1e7\n",
    "                    for trial_size in range(1, MAX_TRIES):\n",
    "                        workforce_dict[0] = trial_size\n",
    "                        if (objval < objvalprev)&(np.isnan(objval) == False):\n",
    "                            objvalprev = objval\n",
    "                            dict_results = run_roster_solver_objval(model, instance_file_weekday, shift_file_weekday, instance_file_weekend, shift_file_weekend, workforce_dict, OC, RM, GM, h_min, h_max, max_n_diff, max_n_shifts)\n",
    "                            objval = dict_results['objective_value'][0]\n",
    "                            print(\"trial_size\",trial_size)\n",
    "                            df_ = pd.DataFrame(dict_results)\n",
    "                            df_['workforce_size_trial'] = trial_size\n",
    "                            list_results.append(df_)\n",
    "                            print(\"trial_size\",trial_size)\n",
    "                        else:\n",
    "                            #keep track of optimal\n",
    "                            dict_out = dict_append_workforce(dict_out, base_file, city, demand_baseline, OC, RM, GM, model, max_n_shifts, trial_size-1, np.nan, objvalprev, objval)\n",
    "                            break\n",
    "                        if trial_size == int(MAX_TRIES-1):\n",
    "                            #keep track of optimal\n",
    "                            dict_out = dict_append_workforce(dict_out, base_file, city, demand_baseline, OC, RM, GM, model, max_n_shifts, trial_size, objvalprev, objval, np.nan)\n",
    "            else:\n",
    "                objvalprev = 1e8\n",
    "                objval = 1e7\n",
    "                for trial_size in range(1, MAX_TRIES):\n",
    "                    workforce_dict[0] = trial_size\n",
    "                    if (objval < objvalprev)&(np.isnan(objval) == False):\n",
    "                        objvalprev = objval\n",
    "                        dict_results = run_roster_solver_objval(model, instance_file_weekday, shift_file_weekday, instance_file_weekend, shift_file_weekend, workforce_dict, OC, RM, GM, h_min, h_max, max_n_diff)\n",
    "                        objval = dict_results['objective_value'][0]\n",
    "                        print(\"trial_size\",trial_size)\n",
    "                        df_ = pd.DataFrame(dict_results)\n",
    "                        df_['workforce_size_trial'] = trial_size\n",
    "                        list_results.append(df_)\n",
    "                    else: \n",
    "                        #keep track of optimal (trial size - 1)\n",
    "                        dict_out = dict_append_workforce(dict_out, base_file, city, demand_baseline, OC, RM, GM, model, np.nan, trial_size-1, np.nan, objvalprev, objval)\n",
    "                        break\n",
    "                    if trial_size == int(MAX_TRIES-1):\n",
    "                        #keep track of optimal\n",
    "                        dict_out = dict_append_workforce(dict_out, base_file, city, demand_baseline, OC, RM, GM, model, np.nan, trial_size, objvalprev, objval, np.nan)\n",
    "    #export optimal workforce size values\n",
    "    with open(workforce_out, 'w') as f:\n",
    "        json.dump(dict_out, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export a concat of all the trial information\n",
    "\n",
    "df_trials = pd.concat(list_results, ignore_index = True)\n",
    "df_trials.to_csv(r'../workforce_size/all_trials.xlsx', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
