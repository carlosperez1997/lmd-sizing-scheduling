{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clarice/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from os import path\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.legend_handler import HandlerTuple\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from os.path import basename, splitext\n",
    "\n",
    "# from solver import Instance\n",
    "\n",
    "from argparse import Namespace\n",
    "import sys\n",
    "sys.path.append('../solver')\n",
    "# from solver_output import practice_print\n",
    "from solver_rostering import run_roster_solver_objval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paris_db=2.00', 'paris_db=0.50', 'paris_db=1.00', 'lyon_db=2.00', 'frankfurt_db=0.50', 'berlin_db=2.00', 'lyon_db=0.50', 'frankfurt_db=1.00', 'berlin_db=0.50', 'frankfurt_db=2.00', 'lyon_db=1.00', 'berlin_db=4.00', 'berlin_db=1.00', 'paris_db=4.00', 'lyon_db=4.00', 'frankfurt_db=4.00']\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "list_city_dt = []\n",
    "\n",
    "for file_in in os.listdir(r'../instances'):\n",
    "    base_file = splitext(basename(file_in))[0]\n",
    "    base_file_split = base_file.split('_')\n",
    "    file = base_file_split[0]+'_'+base_file_split[1]\n",
    "    list_city_dt.append(file)\n",
    "\n",
    "list_city_dt = list(set(list_city_dt))\n",
    "print(list_city_dt)\n",
    "print(len(list_city_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (linux64 - \"Ubuntu 22.04.4 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-8565U CPU @ 1.80GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 99524 rows, 102471 columns and 156227 nonzeros\n",
      "Model fingerprint: 0x5c6f2a5c\n",
      "Variable types: 99120 continuous, 3351 integer (3351 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+10]\n",
      "  Objective range  [3e-02, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 6e+01]\n",
      "Warning: Model contains large matrix coefficients\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Presolve removed 99180 rows and 99127 columns\n",
      "Presolve time: 0.03s\n",
      "Presolved: 344 rows, 3344 columns, 12548 nonzeros\n",
      "Variable types: 0 continuous, 3344 integer (3344 binary)\n",
      "Found heuristic solution: objective 9460.3166667\n",
      "\n",
      "Explored 1 nodes (0 simplex iterations) in 0.07 seconds (0.05 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 9460.32 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 9.460316666666e+03, best bound 9.460316666666e+03, gap 0.0000%\n",
      "Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (linux64 - \"Ubuntu 22.04.4 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-8565U CPU @ 1.80GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 99623 rows, 103042 columns and 171995 nonzeros\n",
      "Model fingerprint: 0xda4319f5\n",
      "Variable types: 99120 continuous, 3922 integer (3922 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+10]\n",
      "  Objective range  [3e-02, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 6e+01]\n",
      "Warning: Model contains large matrix coefficients\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Presolve removed 98813 rows and 100637 columns\n",
      "Presolve time: 0.05s\n",
      "Presolved: 810 rows, 2405 columns, 6940 nonzeros\n",
      "Variable types: 1070 continuous, 1335 integer (1333 binary)\n",
      "Found heuristic solution: objective 9434.9000000\n",
      "\n",
      "Root relaxation: objective 9.384133e+03, 727 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    9384.1333333 9384.13333  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (727 simplex iterations) in 0.11 seconds (0.07 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 9384.13 9434.9 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 9.384133333333e+03, best bound 9.384133333333e+03, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "list_results = []\n",
    "dict_workforce = {}\n",
    "dict_workforce['instance'] = []\n",
    "dict_workforce['OC'] = []\n",
    "dict_workforce['model'] = []\n",
    "dict_workforce['max_n_shifts'] = []\n",
    "dict_workforce['workforce_size'] = []\n",
    "dict_workforce['objective_value'] = []\n",
    "dict_workforce['workforce_size_next'] = []\n",
    "dict_workforce['objective_value_next'] = []\n",
    "\n",
    "MAX_TRIES = 3\n",
    "\n",
    "RM = 1.5\n",
    "GM = 0.8\n",
    "h_min = 32\n",
    "h_max = 48\n",
    "max_n_diff = 3\n",
    "\n",
    "\n",
    "# for base_file in list_city_dt:\n",
    "for base_file in ['berlin_db=1.00']:\n",
    "    weekday_ = f'{base_file}_dt=doublepeak.json'\n",
    "    weekend_ = f'{base_file}_dt=uniform.json'\n",
    "\n",
    "    instance_file_weekday = f\"../instances/{weekday_}\"\n",
    "    instance_file_weekend = f\"../instances/{weekend_}\"\n",
    "\n",
    "    shift_file_weekday = f\"../shifts/{weekday_}\"\n",
    "    shift_file_weekend = f\"../shifts/{weekend_}\"\n",
    "    \n",
    "    # for OC in [1.2, 1.5, 1.8, 2.0, 2.5]:\n",
    "    for OC in [1.5]:\n",
    "        # for model in ['fixed', 'flex', 'partflex']:\n",
    "        for model in ['partflex']:\n",
    "            if model == 'partflex':\n",
    "                # for max_n_shifts in range(2,5):\n",
    "                for max_n_shifts in [2]:\n",
    "                    dict_base = {\n",
    "                        'instance_file':[file],\n",
    "                        'city':[city],\n",
    "                        'demand_baseline':[demand_baseline],\n",
    "                        'model':[model]*n_regions,\n",
    "                        'max_n_shifts':[max_n_shift]*n_regions,\n",
    "                        'outsourcing_cost_multiplier':[OC]*n_regions,\n",
    "                        'regional_multiplier':[RM]*n_regions,\n",
    "                        'global_multiplier':[GM]*n_regions,\n",
    "                        'region':[region for region in range(0,n_regions)]\n",
    "                    }\n",
    "\n",
    "\n",
    "                    objvalprev = 10000000\n",
    "                    objval = 1000000\n",
    "                    for trial_size in range(1, MAX_TRIES):\n",
    "                        workforce_dict = {0:trial_size, 1:1, 2:1, 3:1, 4:1}\n",
    "                        if (objval < objvalprev)&(np.isnan(objval) == False):\n",
    "                            objvalprev = objval\n",
    "                            dict_results = run_roster_solver_objval(model, instance_file_weekday, shift_file_weekday, instance_file_weekend, shift_file_weekend, workforce_dict, OC, RM, GM, h_min, h_max, max_n_diff, max_n_shifts)\n",
    "                            objval = dict_results['objective_value'][0]\n",
    "                            df_ = pd.DataFrame(dict_results)\n",
    "                            df_['workforce_size_trial'] = trial_size\n",
    "                            list_results.append(df_)\n",
    "                        else:\n",
    "                            #keep track of optimal\n",
    "                            dict_workforce['instance'].append(base_file)\n",
    "                            dict_workforce['OC'].append(OC)\n",
    "                            dict_workforce['model'].append(model)\n",
    "                            dict_workforce['max_n_shifts'].append(np.nan)\n",
    "                            dict_workforce['workforce_size'].append(trial_size-1)\n",
    "                            dict_workforce['objective_value'].append(objvalprev)\n",
    "                            dict_workforce['objective_value_next'].append(objval)\n",
    "                            trial_size = 10000000000\n",
    "                        if trial_size == int(MAX_TRIES-1):\n",
    "                            #keep track of optimal\n",
    "                            dict_workforce['instance'].append(base_file)\n",
    "                            dict_workforce['OC'].append(OC)\n",
    "                            dict_workforce['model'].append(model)\n",
    "                            dict_workforce['max_n_shifts'].append(np.nan)\n",
    "                            dict_workforce['workforce_size'].append(trial_size)\n",
    "                            dict_workforce['objective_value'].append(objvalprev)\n",
    "                            dict_workforce['objective_value_next'].append(objval)\n",
    "            else:\n",
    "                objvalprev = 10000000\n",
    "                objval = 1000000\n",
    "                for trial_size in range(1, MAX_TRIES):\n",
    "                    print(\"trial_size\",trial_size)\n",
    "                    workforce_dict = {0:trial_size, 1:1, 2:1, 3:1, 4:1}\n",
    "                    if (objval < objvalprev)&(np.isnan(objval) == False):\n",
    "                        objvalprev = objval\n",
    "                        dict_results = run_roster_solver_objval(model, instance_file_weekday, shift_file_weekday, instance_file_weekend, shift_file_weekend, workforce_dict, OC, RM, GM, h_min, h_max, max_n_diff)\n",
    "                        objval = dict_results['objective_value'][0]\n",
    "                        print(\"objective_value\",objval)\n",
    "                        df_ = pd.DataFrame(dict_results)\n",
    "                        df_['workforce_size_trial'] = trial_size\n",
    "                        list_results.append(df_)\n",
    "                    else: \n",
    "                        #keep track of optimal (trial size - 1)\n",
    "                        dict_workforce['instance'].append(base_file)\n",
    "                        dict_workforce['OC'].append(OC)\n",
    "                        dict_workforce['model'].append(model)\n",
    "                        dict_workforce['max_n_shifts'].append(np.nan)\n",
    "                        dict_workforce['workforce_size'].append(trial_size-1)\n",
    "                        dict_workforce['objective_value'].append(objvalprev)\n",
    "                        dict_workforce['objective_value_next'].append(objval)\n",
    "                        trial_size = 10000000000\n",
    "                    if trial_size == int(MAX_TRIES-1):\n",
    "                        #keep track of optimal\n",
    "                        dict_workforce['instance'].append(base_file)\n",
    "                        dict_workforce['OC'].append(OC)\n",
    "                        dict_workforce['model'].append(model)\n",
    "                        dict_workforce['max_n_shifts'].append(np.nan)\n",
    "                        dict_workforce['workforce_size'].append(trial_size)\n",
    "                        dict_workforce['objective_value'].append(objvalprev)\n",
    "                        dict_workforce['objective_value_next'].append(objval)\n",
    "                        trial_size = 10000000000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instance': ['berlin_db=1.00'],\n",
       " 'OC': [1.5],\n",
       " 'model': ['partflex'],\n",
       " 'max_n_shifts': [nan],\n",
       " 'workforce_size': [2],\n",
       " 'objective_value': [9460.316666666355],\n",
       " 'workforce_size_next': [],\n",
       " 'objective_value_next': [9384.13333333302]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_workforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_workforce['instance'] = []\n",
    "dict_workforce['OC'] = []\n",
    "dict_workforce['model'] = []\n",
    "dict_workforce['max_n_shifts'] = []\n",
    "dict_workforce['workforce_size'] = []\n",
    "dict_workforce['objective_value'] = []\n",
    "dict_workforce['objective_value_next'] = []\n",
    "\n",
    "\n",
    "for file in os.listdir(r'../instances'):\n",
    "    if (file.find('doublepeak') > -1) or (file.find('uniform') > -1):\n",
    "        if file not in os.listdir(r'../workforce_size'):\n",
    "\n",
    "for base_file in ['berlin_db=1.00']:\n",
    "    weekday_ = f'{base_file}_dt=doublepeak.json'\n",
    "    weekend_ = f'{base_file}_dt=uniform.json'\n",
    "\n",
    "    instance_file_weekday = f\"../instances/{weekday_}\"\n",
    "    instance_file_weekend = f\"../instances/{weekend_}\"\n",
    "\n",
    "    shift_file_weekday = f\"../shifts/{weekday_}\"\n",
    "    shift_file_weekend = f\"../shifts/{weekend_}\"\n",
    "\n",
    "\n",
    "    workforce_out = f\"../workforce_size/{base_file}\"\n",
    "    dict_out = {\n",
    "        'instance_file':[],\n",
    "        'city':[],\n",
    "        'demand_baseline':[],\n",
    "        'demand_type':[],\n",
    "        'model':[],\n",
    "        'max_n_shifts':[],\n",
    "        'outsourcing_cost_multiplier':[],\n",
    "        'regional_multiplier':[],\n",
    "        'global_multiplier':[],\n",
    "        'workforce_size':[],\n",
    "        'objective_value':[],\n",
    "        'objective_value_next':[]\n",
    "    }\n",
    "\n",
    "    city_pattern = r'(\\w+)_db'\n",
    "    db_pattern = r'db=(\\d+\\.\\d+)'\n",
    "    dt_pattern = r'dt=(\\w+)'\n",
    "\n",
    "    city_match = re.search(city_pattern, file)\n",
    "    db_match = re.search(db_pattern, file)\n",
    "    dt_match = re.search(dt_pattern, file)\n",
    "    \n",
    "    city = city_match.group(1) if city_match else None\n",
    "    demand_baseline = float(db_match.group(1)) if db_match else None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            for OC in [1.2, 1.5, 1.8, 2.0, 2.5]:\n",
    "                for RM in [1.5]:\n",
    "                    for GM in [0.8]:\n",
    "                        for model in ['fixed','flex','partflex']:\n",
    "                            if model == 'partflex':\n",
    "                                for max_n_shift in range(2,5):\n",
    "                                    dict_shifts, n_regions, dict_raw = run_solver_shift_return(model=model, instance=instance_, outsourcing_cost_multiplier=OC, regional_multiplier=RM, global_multiplier=GM, max_n_shifts=max_n_shift)\n",
    "                                    # if max_n_shift == 2:\n",
    "                                    #     dict_raw_out = dict_raw.copy()\n",
    "                                    dict_base = {\n",
    "                                        'instance_file':[file]*n_regions,\n",
    "                                        'city':[city]*n_regions,\n",
    "                                        'demand_baseline':[demand_baseline]*n_regions,\n",
    "                                        'demand_type':[demand_type]*n_regions,\n",
    "                                        'model':[model]*n_regions,\n",
    "                                        'max_n_shifts':[max_n_shift]*n_regions,\n",
    "                                        'outsourcing_cost_multiplier':[OC]*n_regions,\n",
    "                                        'regional_multiplier':[RM]*n_regions,\n",
    "                                        'global_multiplier':[GM]*n_regions,\n",
    "                                        'region':[region for region in range(0,n_regions)]\n",
    "                                    }\n",
    "                                    list_shift_start = []\n",
    "                                    list_shift_end = []\n",
    "                                    for region in range(0, n_regions):\n",
    "                                        if region in dict_shifts.keys():\n",
    "                                            list_shift_start.append(dict_shifts[region]['shifts_start'])\n",
    "                                            list_shift_end.append(dict_shifts[region]['shifts_end'])\n",
    "                                        else:\n",
    "                                            list_shift_start.append({})\n",
    "                                            list_shift_end.append({})\n",
    "                                    dict_base['shifts_start'] = list_shift_start\n",
    "                                    dict_base['shifts_end'] = list_shift_end\n",
    "                                    for key in dict_base.keys():\n",
    "                                        dict_out[key].extend(dict_base[key])\n",
    "                            else:\n",
    "                                dict_shifts, n_regions, dict_raw = run_solver_shift_return(model=model, instance=instance_, outsourcing_cost_multiplier=OC, regional_multiplier=RM, global_multiplier=GM)\n",
    "                                dict_base = {\n",
    "                                    'instance_file':[file]*n_regions,\n",
    "                                    'city':[city]*n_regions,\n",
    "                                    'demand_baseline':[demand_baseline]*n_regions,\n",
    "                                    'demand_type':[demand_type]*n_regions,\n",
    "                                    'model':[model]*n_regions,\n",
    "                                    'max_n_shifts':[np.nan]*n_regions,\n",
    "                                    'outsourcing_cost_multiplier':[OC]*n_regions,\n",
    "                                    'regional_multiplier':[RM]*n_regions,\n",
    "                                    'global_multiplier':[GM]*n_regions,\n",
    "                                    'region':[region for region in range(0,n_regions)]\n",
    "                                }\n",
    "                                list_shift_start = []\n",
    "                                list_shift_end = []\n",
    "                                for region in range(0, n_regions):\n",
    "                                    if region in dict_shifts.keys():\n",
    "                                        list_shift_start.append(dict_shifts[region]['shifts_start'])\n",
    "                                        list_shift_end.append(dict_shifts[region]['shifts_end'])\n",
    "                                    else:\n",
    "                                        list_shift_start.append({})\n",
    "                                        list_shift_end.append({})\n",
    "                                dict_base['shifts_start'] = list_shift_start\n",
    "                                dict_base['shifts_end'] = list_shift_end\n",
    "                                for key in dict_base.keys():\n",
    "                                    dict_out[key].extend(dict_base[key])\n",
    "\n",
    "            with open(shift_out, 'w') as f:\n",
    "                json.dump(dict_out, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            shift_out = f\"../shifts/{file}\"\n",
    "            dict_out = {\n",
    "                'instance_file':[],\n",
    "                'city':[],\n",
    "                'demand_baseline':[],\n",
    "                'demand_type':[],\n",
    "                'model':[],\n",
    "                'max_n_shifts':[],\n",
    "                'outsourcing_cost_multiplier':[],\n",
    "                'regional_multiplier':[],\n",
    "                'global_multiplier':[],\n",
    "                'region':[],\n",
    "                'shifts_start':[],\n",
    "                'shifts_end':[]\n",
    "            }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
