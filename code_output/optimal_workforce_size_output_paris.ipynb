{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os import path\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from os.path import basename, splitext\n",
    "\n",
    "# from solver import Instance\n",
    "\n",
    "from argparse import Namespace\n",
    "import sys\n",
    "sys.path.append('../solver')\n",
    "# from solver_output import practice_print\n",
    "from solver_rostering import run_roster_solver_objval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['berlin_db=0.50', 'berlin_db=1.00', 'berlin_db=2.00', 'berlin_db=4.00', 'frankfurt_db=0.50', 'frankfurt_db=1.00', 'frankfurt_db=2.00', 'frankfurt_db=4.00', 'lyon_db=0.50', 'lyon_db=1.00', 'lyon_db=2.00', 'lyon_db=4.00', 'paris_db=0.50', 'paris_db=1.00', 'paris_db=2.00', 'paris_db=4.00']\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "list_city_dt = []\n",
    "\n",
    "for file_in in os.listdir(r'../instances'):\n",
    "    base_file = splitext(basename(file_in))[0]\n",
    "    base_file_split = base_file.split('_')\n",
    "    file = base_file_split[0]+'_'+base_file_split[1]\n",
    "    list_city_dt.append(file)\n",
    "\n",
    "list_city_dt = list(set(list_city_dt))\n",
    "list_city_dt.sort()\n",
    "print(list_city_dt)\n",
    "print(len(list_city_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paris_db=0.50', 'paris_db=1.00', 'paris_db=2.00', 'paris_db=4.00']\n"
     ]
    }
   ],
   "source": [
    "#Subset to France\n",
    "\n",
    "list_city_dt_subset = []\n",
    "\n",
    "for city_db in list_city_dt:\n",
    "    if (city_db.find('paris') > -1):\n",
    "        list_city_dt_subset.append(city_db)\n",
    "\n",
    "print(list_city_dt_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dict_append_workforce(dict_, base_file, city, demand_baseline, OC, RM, GM, model, max_n_shifts, workforce_size, objvalprev, objval, objvalnext):\n",
    "    dict_['instance_file_base'].append(base_file)\n",
    "    dict_['city'].append(city)\n",
    "    dict_['demand_baseline'].append(demand_baseline)\n",
    "    dict_['model'].append(model)\n",
    "    dict_['max_n_shifts'].append(max_n_shifts)\n",
    "    dict_['outsourcing_cost_multiplier'].append(OC)\n",
    "    dict_['regional_multiplier'].append(RM)\n",
    "    dict_['global_multiplier'].append(GM)\n",
    "    dict_['workforce_size_region0'].append(workforce_size)\n",
    "    dict_['objective_value_prev'].append(objvalprev)\n",
    "    dict_['objective_value'].append(objval)\n",
    "    dict_['objective_value_next'].append(objvalnext)\n",
    "    return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (3669027997.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    for base_file in ['paris_db=0.50', 'paris_db=1.00']\u001b[0m\n\u001b[0m                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "#Code that determines optimal workforce size\n",
    "\n",
    "MAX_TRIES = 120\n",
    "\n",
    "RM = 1.5\n",
    "GM = 0.8\n",
    "h_min = 32\n",
    "h_max = 48\n",
    "max_n_diff = 3\n",
    "\n",
    "#for base_file in list_city_dt_subset:\n",
    "for base_file in ['paris_db=0.50', 'paris_db=1.00']:\n",
    "    print(base_file+'============================================')\n",
    "\n",
    "    if f'{base_file}.json' not in os.listdir(r'../workforce_size'):\n",
    "\n",
    "        list_results = []\n",
    "\n",
    "        #create inputs to run a trial workforce size\n",
    "        weekday_ = f'{base_file}_dt=doublepeak.json'\n",
    "        weekend_ = f'{base_file}_dt=uniform.json'\n",
    "\n",
    "        instance_file_weekday = f\"../instances/{weekday_}\"\n",
    "        instance_file_weekend = f\"../instances/{weekend_}\"\n",
    "\n",
    "        shift_file_weekday = f\"../shifts/{weekday_}\"\n",
    "        shift_file_weekend = f\"../shifts/{weekend_}\"\n",
    "\n",
    "        #create dictionary for evaluating optimal workforce size\n",
    "        workforce_out = f\"../workforce_size/{base_file}.json\"\n",
    "        dict_out = {\n",
    "            'instance_file_base':[],\n",
    "            'city':[],\n",
    "            'demand_baseline':[],\n",
    "            'model':[],\n",
    "            'max_n_shifts':[],\n",
    "            'outsourcing_cost_multiplier':[],\n",
    "            'regional_multiplier':[],\n",
    "            'global_multiplier':[],\n",
    "            'workforce_size_region0':[],\n",
    "            'objective_value_prev':[],\n",
    "            'objective_value':[],\n",
    "            'objective_value_next':[]\n",
    "        }\n",
    "\n",
    "        city_pattern = r'(\\w+)_db'\n",
    "        db_pattern = r'db=(\\d+\\.\\d+)'\n",
    "\n",
    "        city_match = re.search(city_pattern, base_file)\n",
    "        db_match = re.search(db_pattern, base_file)\n",
    "\n",
    "        city = city_match.group(1) if city_match else None\n",
    "        demand_baseline = float(db_match.group(1)) if db_match else None\n",
    "\n",
    "        #Set min_tries based on demand_baseline\n",
    "        if demand_baseline == 0.5:\n",
    "            MIN_TRIES = 5\n",
    "        elif demand_baseline == 1.0:\n",
    "            MIN_TRIES = 15\n",
    "        elif demand_baseline == 2.0:\n",
    "            MIN_TRIES = 25\n",
    "        elif demand_baseline == 4.0:\n",
    "            MIN_TRIES = 35\n",
    "\n",
    "        for OC in [1.2, 1.5, 1.8, 2.0, 2.5]:\n",
    "        # for OC in [1.2]:\n",
    "            print(f'OC = {OC}++++++++++++++++++++++')\n",
    "            for model in ['fixed', 'flex', 'partflex']:\n",
    "            # for model in ['fixed']:\n",
    "                print(f'model = {model}-------------------------')\n",
    "                if model == 'partflex':\n",
    "                    for max_n_shifts in range(2,5):\n",
    "                    # for max_n_shifts in [4]:\n",
    "                        objvalprev = 1e8\n",
    "                        objval = 1e7\n",
    "                        for trial_size in range(MIN_TRIES, MAX_TRIES):\n",
    "                            workforce_dict = {0:trial_size, 1:1, 2:1, 3:1, 4:1}\n",
    "                            if (objval < objvalprev)&(np.isnan(objval) == False):\n",
    "                                objvalprev = objval\n",
    "                                dict_results = run_roster_solver_objval(model, instance_file_weekday, shift_file_weekday, instance_file_weekend, shift_file_weekend, workforce_dict, OC, RM, GM, h_min, h_max, max_n_diff, max_n_shifts)\n",
    "                                objval = dict_results['objective_value'][0]\n",
    "                                print(\"trial_size\",trial_size)\n",
    "                                df_ = pd.DataFrame(dict_results)\n",
    "                                df_['workforce_size_trial'] = trial_size\n",
    "                                list_results.append(df_)\n",
    "                            else:\n",
    "                                #keep track of optimal\n",
    "                                dict_out = dict_append_workforce(dict_out, base_file, city, demand_baseline, OC, RM, GM, model, max_n_shifts, trial_size-1, np.nan, objvalprev, objval)\n",
    "                                break\n",
    "                            if trial_size == int(MAX_TRIES-1):\n",
    "                                #keep track of optimal\n",
    "                                dict_out = dict_append_workforce(dict_out, base_file, city, demand_baseline, OC, RM, GM, model, max_n_shifts, trial_size, objvalprev, objval, np.nan)\n",
    "                else:\n",
    "                    objvalprev = 1e8\n",
    "                    objval = 1e7\n",
    "                    for trial_size in range(MIN_TRIES, MAX_TRIES):\n",
    "                        workforce_dict = {0:trial_size, 1:1, 2:1, 3:1, 4:1}\n",
    "                        if (objval < objvalprev)&(np.isnan(objval) == False):\n",
    "                            objvalprev = objval\n",
    "                            dict_results = run_roster_solver_objval(model, instance_file_weekday, shift_file_weekday, instance_file_weekend, shift_file_weekend, workforce_dict, OC, RM, GM, h_min, h_max, max_n_diff)\n",
    "                            objval = dict_results['objective_value'][0]\n",
    "                            print(\"trial_size\",trial_size)\n",
    "                            df_ = pd.DataFrame(dict_results)\n",
    "                            df_['workforce_size_trial'] = trial_size\n",
    "                            list_results.append(df_)\n",
    "                        else: \n",
    "                            #keep track of optimal (trial size - 1)\n",
    "                            dict_out = dict_append_workforce(dict_out, base_file, city, demand_baseline, OC, RM, GM, model, np.nan, trial_size-1, np.nan, objvalprev, objval)\n",
    "                            break\n",
    "                        if trial_size == int(MAX_TRIES-1):\n",
    "                            #keep track of optimal\n",
    "                            dict_out = dict_append_workforce(dict_out, base_file, city, demand_baseline, OC, RM, GM, model, np.nan, trial_size, objvalprev, objval, np.nan)\n",
    "        #export optimal workforce size values\n",
    "        with open(workforce_out, 'w') as f:\n",
    "            json.dump(dict_out, f, indent=2)\n",
    "        df_trials = pd.concat(list_results, ignore_index = True)\n",
    "        df_trials.to_excel(f'../workforce_size/{base_file}_all_trials.xlsx', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
